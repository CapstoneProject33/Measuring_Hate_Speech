{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{swayamdipta2020dataset,\n",
    "    title={Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics},\n",
    "    author={Swabha Swayamdipta and Roy Schwartz and Nicholas Lourie and Yizhong Wang and Hannaneh Hajishirzi and Noah A. Smith and Yejin Choi},\n",
    "    booktitle={Proceedings of EMNLP},\n",
    "    url={https://arxiv.org/abs/2009.10795},\n",
    "    year={2020}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dependencies: Transformers, pandas, and other required libraries are assumed to be pre-installed.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_path = 'data/Measuring Hate Speech.csv'\n",
    "output_dir = f\"cartography_output_{str(uuid.uuid4())[:8]}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "text_column = 'text'\n",
    "label_column = 'hatespeech'\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(data_path)\n",
    "df = df[[text_column, label_column]]  # Modify this to match the columns in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "df['input_ids'] = df[text_column].apply(lambda x: tokenizer.encode(x, truncation=True, padding='max_length'))\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save split datasets to JSONL format for cartography training\n",
    "def save_to_jsonl(df, file_name):\n",
    "    df_list = df[['input_ids', label_column]].to_dict(orient='records')\n",
    "    with open(file_name, 'w') as f:\n",
    "        for record in df_list:\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "\n",
    "save_to_jsonl(train_df, f'{output_dir}/train.jsonl')\n",
    "save_to_jsonl(val_df, f'{output_dir}/val.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config file for cartography model\n",
    "config = {\n",
    "    \"data_dir\": output_dir,\n",
    "    \"model_type\": \"roberta\",\n",
    "    \"model_name_or_path\": \"roberta-base\",\n",
    "    \"task_name\": \"hate_speech\",\n",
    "    \"seed\": 42,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"features_cache_dir\": f\"{output_dir}/cache\",\n",
    "    \"per_gpu_train_batch_size\": 16\n",
    "}\n",
    "\n",
    "# Save config file\n",
    "with open(f'{output_dir}/config.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/knify/Documents/401 Capstone Measuring Hate Speech/cartography/cartography/classification/run_glue.py\", line 46, in <module>\n",
      "    from cartography.classification.glue_utils import adapted_glue_compute_metrics as compute_metrics\n",
      "ModuleNotFoundError: No module named 'cartography.classification'\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/knify/Documents/401 Capstone Measuring Hate Speech/cartography/cartography/selection/train_dy_filtering.py\", line 17, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/seaborn/__init__.py\", line 13, in <module>\n",
      "    from .matrix import *\n",
      "  File \"/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/seaborn/matrix.py\", line 14, in <module>\n",
      "    from . import cm\n",
      "  File \"/Users/knify/Documents/401 Capstone Measuring Hate Speech/venv/lib/python3.9/site-packages/seaborn/cm.py\", line 1055, in <module>\n",
      "    mpl_cm.register_cmap(_name, _cmap)\n",
      "AttributeError: module 'matplotlib.cm' has no attribute 'register_cmap'\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/CapstoneProject33/cartography/\n",
    "\n",
    "# Train model using cartography\n",
    "!python -m cartography.cartography.classification.run_glue -c {output_dir}/config.json --do_train --do_eval -o {output_dir}\n",
    "\n",
    "# Plotting training dynamics using cartography\n",
    "!python -m cartography.cartography.selection.train_dy_filtering --plot --task_name \"hate_speech\" --model_dir {output_dir} --model \"roberta-base\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
